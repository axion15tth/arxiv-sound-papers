{
  "papers": [
    {
      "id": "2602.06043",
      "arxivId": "2602.06043",
      "title": "Shared LoRA Subspaces for almost Strict Continual Learning",
      "authors": [
        "Prakhar Kaushik",
        "Ankit Vaidya",
        "Shravan Chaudhari",
        "Rama Chellappa",
        "Alan Yuille"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "abstract": "Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands, they lack mechanisms for strict continual learning and knowledge integration, without relying on data replay, or multiple adapters. We propose Share, a novel approach to parameter efficient continual finetuning that learns and dynamically updates a single, shared low-rank subspace, enabling seamless adaptation across multiple tasks and modalities. Share constructs a foundational subspace that extracts core knowledge from past tasks and incrementally integrates new information by identifying essential subspace directions. Knowledge from each new task is incorporated into this evolving subspace, facilitating forward knowledge transfer, while minimizing catastrophic interference. This approach achieves up to 100x parameter reduction and 281x memory savings over traditional LoRA methods, maintaining performance comparable to jointly trained models. A single Share model can replace hundreds of task-specific LoRA adapters, supporting scalable, asynchronous continual learning. Experiments across image classification, natural language understanding, 3D pose estimation, and text-to-image generation validate its effectiveness, making Share a practical and scalable solution for lifelong learning in large-scale AI systems.",
      "url": "https://arxiv.org/abs/2602.06043",
      "pdfUrl": "https://arxiv.org/pdf/2602.06043.pdf",
      "titleJa": "ほぼ厳密な継続学習のための共有 LoRA サブスペース"
    },
    {
      "id": "2602.06039",
      "arxivId": "2602.06039",
      "title": "DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching",
      "authors": [
        "Yuxing Lu",
        "Yucheng Hu",
        "Xukai Zhao",
        "Jiuxin Cao"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI"
      ],
      "abstract": "Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \\key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.",
      "url": "https://arxiv.org/abs/2602.06039",
      "pdfUrl": "https://arxiv.org/pdf/2602.06039.pdf",
      "titleJa": "DyTopo: セマンティックマッチングによるマルチエージェント推論のための動的トポロジルーティング"
    },
    {
      "id": "2602.06038",
      "arxivId": "2602.06038",
      "title": "CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction",
      "authors": [
        "Xiaopan Zhang",
        "Zejin Wang",
        "Zhixu Li",
        "Jianpeng Yao",
        "Jiachen Li"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "abstract": "To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this component of the problem, we formalize the information-gathering process in a fully cooperative setting as an underexplored multi-agent multi-task Embodied Question Answering (MM-EQA) problem, which is a novel extension of canonical Embodied Question Answering (EQA), where effective communication is crucial for coordinating efforts without redundancy. To address this problem, we propose CommCP, a novel LLM-based decentralized communication framework designed for MM-EQA. Our framework employs conformal prediction to calibrate the generated messages, thereby minimizing receiver distractions and enhancing communication reliability. To evaluate our framework, we introduce an MM-EQA benchmark featuring diverse, photo-realistic household scenarios with embodied questions. Experimental results demonstrate that CommCP significantly enhances the task success rate and exploration efficiency over baselines. The experiment videos, code, and dataset are available on our project website: https://comm-cp.github.io.",
      "url": "https://arxiv.org/abs/2602.06038",
      "pdfUrl": "https://arxiv.org/pdf/2602.06038.pdf",
      "titleJa": "CommCP: コンフォーマル予測を用いたLLMベース通信による効率的なマルチエージェント協調"
    },
    {
      "id": "2602.06025",
      "arxivId": "2602.06025",
      "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
      "authors": [
        "Haozhen Zhang",
        "Haodong Yue",
        "Tao Feng",
        "Quanyu Long",
        "Jianzhu Bao",
        "Bowen Jin",
        "Weizhi Zhang",
        "Xiao Li",
        "Jiaxuan You",
        "Chengwei Qin",
        "Wenya Wang"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "abstract": "Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \\textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \\textsc{Low}/\\textsc{Mid}/\\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.",
      "url": "https://arxiv.org/abs/2602.06025",
      "pdfUrl": "https://arxiv.org/pdf/2602.06025.pdf",
      "titleJa": "ランタイムエージェントメモリのクエリ対応予算層ルーティングの学習"
    },
    {
      "id": "2602.06023",
      "arxivId": "2602.06023",
      "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments",
      "authors": [
        "Christopher A. McClurg",
        "Alan R. Wagner"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "abstract": "Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.",
      "url": "https://arxiv.org/abs/2602.06023",
      "pdfUrl": "https://arxiv.org/pdf/2602.06023.pdf",
      "titleJa": "仮想現実実験からイベントベースシューティングモデルを学習する"
    },
    {
      "id": "2602.06022",
      "arxivId": "2602.06022",
      "title": "Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering",
      "authors": [
        "Miranda Muqing Miao",
        "Young-Min Cho",
        "Lyle Ungar"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "abstract": "Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimize proxies for correctness rather than correctness itself. We introduce CORAL (Correctness-Optimized Residual Activation Lens), a regularized inference-time steering method that captures distributed correctness signals from model internal activations using weight-decay MLP probes. We evaluate CORAL across three 7B-parameter models and find that it consistently improves accuracy by 10\\% and expected calibration error (ECE) by 50\\% on average. We additionally demonstrate that these gains transfer without retraining to the complete published test sets of four held-out benchmarks (ARC-Challenge, HellaSwag, Math-MC, OpenBookQA), averaging 14\\% accuracy improvements and 49\\% ECE improvements. Our results support the hypothesis that distributed information in model internals can be extracted using regularized probes when individual neurons are insufficient. CORAL thus provides a compute-efficient, transferable, and calibration-aware approach to improve MCQA performance during inference.",
      "url": "https://arxiv.org/abs/2602.06022",
      "pdfUrl": "https://arxiv.org/pdf/2602.06022.pdf",
      "titleJa": "正確性最適化残差活性化レンズ（CORAL）：転送可能でキャリブレーションを考慮した推論時間ステアリング"
    },
    {
      "id": "2602.06014",
      "arxivId": "2602.06014",
      "title": "Optimism Stabilizes Thompson Sampling for Adaptive Inference",
      "authors": [
        "Shunxing Yan",
        "Han Zhong"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST",
        "stat.ML"
      ],
      "abstract": "Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \\emph{optimism} as a key mechanism for restoring \\emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \\citep{halder2025stable} is stable for any $K \\ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \\citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.",
      "url": "https://arxiv.org/abs/2602.06014",
      "pdfUrl": "https://arxiv.org/pdf/2602.06014.pdf",
      "titleJa": "楽観主義は適応推論におけるトンプソンサンプリングを安定化させる"
    },
    {
      "id": "2602.06013",
      "arxivId": "2602.06013",
      "title": "GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?",
      "authors": [
        "Ruihang Li",
        "Leigang Qu",
        "Jingxu Zhang",
        "Dongnan Gui",
        "Mengde Xu",
        "Xiaosong Zhang",
        "Han Hu",
        "Wenjie Wang",
        "Jiaqi Wang"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "abstract": "The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide spectrum of visual generation tasks. Our analysis reveals that this paradigm is limited due to stochastic inconsistency and poor alignment with human perception. To resolve these limitations, we introduce GenArena, a unified evaluation framework that leverages a pairwise comparison paradigm to ensure stable and human-aligned evaluation. Crucially, our experiments uncover a transformative finding that simply adopting this pairwise protocol enables off-the-shelf open-source models to outperform top-tier proprietary models. Notably, our method boosts evaluation accuracy by over 20% and achieves a Spearman correlation of 0.86 with the authoritative LMArena leaderboard, drastically surpassing the 0.36 correlation of pointwise methods. Based on GenArena, we benchmark state-of-the-art visual generation models across diverse tasks, providing the community with a rigorous and automated evaluation standard for visual generation.",
      "url": "https://arxiv.org/abs/2602.06013",
      "pdfUrl": "https://arxiv.org/pdf/2602.06013.pdf",
      "titleJa": "GenArena: 視覚生成タスクに対して人間に合わせた評価を実現するにはどうすればよいでしょうか?"
    },
    {
      "id": "2602.06008",
      "arxivId": "2602.06008",
      "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
      "authors": [
        "Xianyang Liu",
        "Shangding Gu",
        "Dawn Song"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "abstract": "Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.",
      "url": "https://arxiv.org/abs/2602.06008",
      "pdfUrl": "https://arxiv.org/pdf/2602.06008.pdf",
      "titleJa": "AgenticPay: 買い手と売り手の取引のためのマルチエージェントLLM交渉システム"
    },
    {
      "id": "2602.06000",
      "arxivId": "2602.06000",
      "title": "Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods",
      "authors": [
        "Ali Shendabadi",
        "Parnia Izadirad",
        "Mostafa Salehi",
        "Mahmoud Bijankhan"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "abstract": "Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.",
      "url": "https://arxiv.org/abs/2602.06000",
      "pdfUrl": "https://arxiv.org/pdf/2602.06000.pdf",
      "titleJa": "OpenAIのささやき表現と注意深いプーリング手法を活用した音声感情認識"
    },
    {
      "id": "2602.05993",
      "arxivId": "2602.05993",
      "title": "Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps",
      "authors": [
        "Peter Holderrieth",
        "Douglas Chen",
        "Luca Eyring",
        "Ishin Shah",
        "Giri Anantharaman",
        "Yutong He",
        "Zeynep Akata",
        "Tommi Jaakkola",
        "Nicholas Matthew Boffi",
        "Max Simchowitz"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "abstract": "Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an afterthought, and redesign the model for adaptability. We propose \"Diamond Maps\", stochastic flow map models that enable efficient and accurate alignment to arbitrary rewards at inference time. Diamond Maps amortize many simulation steps into a single-step sampler, like flow maps, while preserving the stochasticity required for optimal reward alignment. This design makes search, sequential Monte Carlo, and guidance scalable by enabling efficient and consistent estimation of the value function. Our experiments show that Diamond Maps can be learned efficiently via distillation from GLASS Flows, achieve stronger reward alignment performance, and scale better than existing methods. Our results point toward a practical route to generative models that can be rapidly adapted to arbitrary preferences and constraints at inference time.",
      "url": "https://arxiv.org/abs/2602.05993",
      "pdfUrl": "https://arxiv.org/pdf/2602.05993.pdf",
      "titleJa": "ダイヤモンドマップ：確率的フローマップによる効率的な報酬調整"
    },
    {
      "id": "2602.05986",
      "arxivId": "2602.05986",
      "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
      "authors": [
        "Mingxin Liu",
        "Shuran Ma",
        "Shibei Meng",
        "Xiangyu Zhao",
        "Zicheng Zhang",
        "Shaofeng Zhang",
        "Zhihang Zhong",
        "Peixian Chen",
        "Haoyu Cao",
        "Xing Sun",
        "Haodong Duan",
        "Xue Yang"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "abstract": "While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: \\textit{Reasoning Alignment}, \\textit{Temporal Consistency}, \\textit{Physical Rationality}, and \\textit{Visual Quality}. To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.",
      "url": "https://arxiv.org/abs/2602.05986",
      "pdfUrl": "https://arxiv.org/pdf/2602.05986.pdf",
      "titleJa": "RISE-Video: ビデオジェネレーターは暗黙の世界ルールを解読できるか?"
    },
    {
      "id": "2602.05983",
      "arxivId": "2602.05983",
      "title": "Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins",
      "authors": [
        "Krešimir Kušić",
        "Vinny Cahill",
        "Ivana Dusparic"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI"
      ],
      "abstract": "The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate predicted traffic conditions in addition to real-time observations. Due to the spatio-temporal complexity and the time-variant, non-linear nature of traffic dynamics, predicting motorway traffic remains a difficult problem. Sequence-based deep-learning models offer clear advantages over classical machine learning and statistical models in capturing long-range, temporal dependencies in time-series traffic data, yet limitations in forecasting accuracy and model complexity point to the need for further improvements. To improve motorway traffic forecasting, this paper introduces a Geographically-aware Transformer-based Traffic Forecasting GATTF model, which exploits the geographical relationships between distributed sensors using their mutual information (MI). The model has been evaluated using real-time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer, without increasing model complexity.",
      "url": "https://arxiv.org/abs/2602.05983",
      "pdfUrl": "https://arxiv.org/pdf/2602.05983.pdf",
      "titleJa": "都市高速道路デジタルツインのための地理情報を考慮したトランスフォーマーベースの交通予測"
    },
    {
      "id": "2602.05977",
      "arxivId": "2602.05977",
      "title": "Clifford Kolmogorov-Arnold Networks",
      "authors": [
        "Matthias Wolff",
        "Francesco Alesiani",
        "Christof Duhme",
        "Xiaoyi Jiang"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "abstract": "We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimensional algebras. Our ClKAN also introduces new batch normalization strategies to deal with variable domain input. ClKAN finds application in scientific discovery and engineering, and is validated in synthetic and physics inspired tasks.",
      "url": "https://arxiv.org/abs/2602.05977",
      "pdfUrl": "https://arxiv.org/pdf/2602.05977.pdf",
      "titleJa": "クリフォード・コルモゴロフ＝アーノルド・ネットワークス"
    },
    {
      "id": "2602.05970",
      "arxivId": "2602.05970",
      "title": "Inverse Depth Scaling From Most Layers Being Similar",
      "authors": [
        "Yizhou Liu",
        "Sara Kangaslahti",
        "Ziming Liu",
        "Jeff Gore"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "stat.ML"
      ],
      "abstract": "Neural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely proportional to depth in LLMs, probably due to functionally similar layers reducing error through ensemble averaging rather than compositional learning or discretizing smooth dynamics. This regime is inefficient yet robust and may arise from the architectural bias of residual networks and target functions incompatible with smooth dynamics. The findings suggest that improving LLM efficiency may require architectural innovations to encourage compositional use of depth.",
      "url": "https://arxiv.org/abs/2602.05970",
      "pdfUrl": "https://arxiv.org/pdf/2602.05970.pdf",
      "titleJa": "ほとんどのレイヤーが類似していることによる逆深度スケーリング"
    },
    {
      "id": "2602.05966",
      "arxivId": "2602.05966",
      "title": "LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation",
      "authors": [
        "Mirlan Karimov",
        "Teodora Spasojevic",
        "Markus Braun",
        "Julian Wiederer",
        "Vasileios Belagiannis",
        "Marc Pollefeys"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "abstract": "Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, limiting their utility as scalable and generalizable data engines. In this work, we propose Localized Semantic Alignment (LSA), a simple yet effective framework for fine-tuning pre-trained video generation models. LSA enhances temporal consistency by aligning semantic features between ground-truth and generated video clips. Specifically, we compare the output of an off-the-shelf feature extraction model between the ground-truth and generated video clips localized around dynamic objects inducing a semantic feature consistency loss. We fine-tune the base model by combining this loss with the standard diffusion loss. The model fine-tuned for a single epoch with our novel loss outperforms the baselines in common video generation evaluation metrics. To further test the temporal consistency in generated videos we adapt two additional metrics from object detection task, namely mAP and mIoU. Extensive experiments on nuScenes and KITTI datasets show the effectiveness of our approach in enhancing temporal consistency in video generation without the need for external control signals during inference and any computational overheads.",
      "url": "https://arxiv.org/abs/2602.05966",
      "pdfUrl": "https://arxiv.org/pdf/2602.05966.pdf",
      "titleJa": "LSA: 交通ビデオ生成における時間的一貫性を高めるための局所的な意味的アライメント"
    },
    {
      "id": "2602.05965",
      "arxivId": "2602.05965",
      "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
      "authors": [
        "Joseph Fioresi",
        "Parth Parag Kulkarni",
        "Ashmal Vayani",
        "Song Wang",
        "Mubarak Shah"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "abstract": "Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently reason about similar sub-problems or execute analogous steps, they repeatedly perform substantial overlapping computation. To address these limitations, in this paper, we propose Learning to Share (LTS), a learned shared-memory mechanism for parallel agentic frameworks that enables selective cross-team information reuse while controlling context growth. LTS introduces a global memory bank accessible to all teams and a lightweight controller that decides whether intermediate agent steps should be added to memory or not. The controller is trained using stepwise reinforcement learning with usage-aware credit assignment, allowing it to identify information that is globally useful across parallel executions. Experiments on the AssistantBench and GAIA benchmarks show that LTS significantly reduces overall runtime while matching or improving task performance compared to memory-free parallel baselines, demonstrating that learned memory admission is an effective strategy for improving the efficiency of parallel agentic systems. Project page: https://joefioresi718.github.io/LTS_webpage/",
      "url": "https://arxiv.org/abs/2602.05965",
      "pdfUrl": "https://arxiv.org/pdf/2602.05965.pdf",
      "titleJa": "共有を学ぶ：効率的な並列エージェントシステムのための選択的メモリ"
    },
    {
      "id": "2602.05951",
      "arxivId": "2602.05951",
      "title": "Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching",
      "authors": [
        "Junwan Kim",
        "Jiho Park",
        "Seonghu Jeon",
        "Seungryong Kim"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "abstract": "Flow matching has recently emerged as a promising alternative to diffusion-based generative models, particularly for text-to-image generation. Despite its flexibility in allowing arbitrary source distributions, most existing approaches rely on a standard Gaussian distribution, a choice inherited from diffusion models, and rarely consider the source distribution itself as an optimization target in such settings. In this work, we show that principled design of the source distribution is not only feasible but also beneficial at the scale of modern text-to-image systems. Specifically, we propose learning a condition-dependent source distribution under flow matching objective that better exploit rich conditioning signals. We identify key failure modes that arise when directly incorporating conditioning into the source, including distributional collapse and instability, and show that appropriate variance regularization and directional alignment between source and target are critical for stable and effective learning. We further analyze how the choice of target representation space impacts flow matching with structured sources, revealing regimes in which such designs are most effective. Extensive experiments across multiple text-to-image benchmarks demonstrate consistent and robust improvements, including up to a 3x faster convergence in FID, highlighting the practical benefits of a principled source distribution design for conditional flow matching.",
      "url": "https://arxiv.org/abs/2602.05951",
      "pdfUrl": "https://arxiv.org/pdf/2602.05951.pdf",
      "titleJa": "より良い情報源、より良い流れ：フローマッチングのための条件依存の情報源分布の学習"
    },
    {
      "id": "2602.05930",
      "arxivId": "2602.05930",
      "title": "Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025",
      "authors": [
        "Samar Ansari"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "abstract": "Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Information Processing Systems (NeurIPS), one of the world's most prestigious AI conferences. Despite review by 3-5 expert researchers per paper, these fabricated citations evaded detection, appearing in 53 published papers (approx. 1% of all accepted papers). We develop a five-category taxonomy that classifies hallucinations by their failure mode: Total Fabrication (66%), Partial Attribute Corruption (27%), Identifier Hijacking (4%), Placeholder Hallucination (2%), and Semantic Hallucination (1%). Our analysis reveals a critical finding: every hallucination (100%) exhibited compound failure modes. The distribution of secondary characteristics was dominated by Semantic Hallucination (63%) and Identifier Hijacking (29%), which often appeared alongside Total Fabrication to create a veneer of plausibility and false verifiability. These compound structures exploit multiple verification heuristics simultaneously, explaining why peer review fails to detect them. The distribution exhibits a bimodal pattern: 92% of contaminated papers contain 1-2 hallucinations (minimal AI use) while 8% contain 4-13 hallucinations (heavy reliance). These findings demonstrate that current peer review processes do not include effective citation verification and that the problem extends beyond NeurIPS to other major conferences, government reports, and professional consulting. We propose mandatory automated citation verification at submission as an implementable solution to prevent fabricated citations from becoming normalized in scientific literature.",
      "url": "https://arxiv.org/abs/2602.05930",
      "pdfUrl": "https://arxiv.org/pdf/2602.05930.pdf",
      "titleJa": "エリート査読における複合的な欺瞞：NeurIPS 2025における捏造された100件の引用の失敗モード分類"
    },
    {
      "id": "2602.05920",
      "arxivId": "2602.05920",
      "title": "Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem",
      "authors": [
        "Eva Andrés"
      ],
      "publishedDate": "2026-02-05",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "abstract": "This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.",
      "url": "https://arxiv.org/abs/2602.05920",
      "pdfUrl": "https://arxiv.org/pdf/2602.05920.pdf",
      "titleJa": "容量付き車両経路問題のためのトランスフォーマーを用いた量子強化学習"
    }
  ],
  "lastUpdated": "2026-02-08T01:23:42.321652",
  "totalCount": 20
}